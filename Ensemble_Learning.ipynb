{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNT7EpwlUh5BKVv6NqKwFlg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adharsh0001/Machine-Learning/blob/main/Ensemble_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voting Classifier Algorithm"
      ],
      "metadata": {
        "id": "67V9fbxvcnCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Required Packages\n",
        "\n",
        "Getting the data\n",
        "\n",
        "Clean the data"
      ],
      "metadata": {
        "id": "BtGCyyW7XVc2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeMdLjeVHnkL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"\")\n",
        "df.shape\n",
        "df.isnull().sum()\n",
        "df.Gender.value_counts()\n",
        "df[\"Gender\"].fillna(\"Male\",inplace = True)\n",
        "df.Married.value_counts()\n",
        "df[\"Married\"].fillna(\"yes\",inplace = True)\n",
        "# Do the imputing for all the columns with Null values\n",
        "\n",
        "df = df.fillna(df.median())\n",
        "# My data is clean\n",
        "# check the data if it is in right format"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Credit_History\"] = df[\"Credit_History\"].astype(\"int\")"
      ],
      "metadata": {
        "id": "OhXRPdmMTHVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "del df[\"Loan_ID\"]\n",
        "\n",
        "dfT = df\n",
        "\n",
        "#Encoding\n",
        "dfT[\"Gender\"] = dfT[\"Gender\"].map({\"Male\":0,\"Female\":1}) #Binary - Label Encoder\n",
        "dfT[\"Married\"] = dfT[\"Married\"].map({\"Yes\":0,\"No\":1})    #Binary - Label Encoder\n",
        "dfT = pd.get_dummies(dfT,columns = [\"Property_Area\"])    #Multi-class Nominal - One Hot Encoding"
      ],
      "metadata": {
        "id": "jjtGnSmSVIz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train,y_test = train_test_split(dfT(dfT.columns[:,-1],dfT[\"Loan_Status\"].values,test_size = 0.25)"
      ],
      "metadata": {
        "id": "8jCprLi1XbjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "std = StandardScaler()\n",
        "X_train = std.fit_transform(X_train)\n",
        "X_test = std.transform(X_test)"
      ],
      "metadata": {
        "id": "lFDb0pPIXwlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassfier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "model1 = LogisticRegression(random_state =1)\n",
        "model2 = tree.DecisionTreeClassifier(random_state = 1)\n",
        "model3 = KNeighborsClassifer(3)\n",
        "model = VotingClassifier(estimator = [(\"lr\",model1),(\"dt\",model2),(\"knn\",model3)],voting =\"soft\")\n",
        "model.fit(X_train,y_train)\n",
        "preds = model.predict(X_test)\n",
        "model.score(X_test,y_test)\n",
        "roc_auc_score(y_test,model.predict_proba(X_test)[:,1])"
      ],
      "metadata": {
        "id": "zyu3K9nWYF9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "2EDxosydcuvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "original_features = pd.read_scv(\"temp.csv\")\n",
        "print(original_features.columns)\n",
        "original_features\n",
        "\n",
        "original_features.isnull().sum()\n",
        "# For decision tree, encoding is not mandatory hence we use label encoder for weeks column\n",
        "original_features.week = original_features.week.map({\"sun\":1,\"mon\":2,\"tue\":3,\"wed\":4,\"thur\":5,\"fri\":6,\"sat\":7})\n",
        "\n",
        "import numpy as np\n",
        "original_labels = np.array(original_features[\"actual\"])\n",
        "\n",
        "original_features = original_features.drop(\"friend\",axis =1)\n",
        "original_features = original_features.drop(\"actual\",axis =1)\n",
        "\n",
        "original_feature_list = list(original_features.columns)\n",
        "\n",
        "original_features = np.array(original_features)\n",
        "original_features\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(original_features, original_labels,test_size =0.2)"
      ],
      "metadata": {
        "id": "tn7P7cXCcxUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initiating and applying the RandomForest Model"
      ],
      "metadata": {
        "id": "zcf0vS7ChHSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators =100, max_depth = 3, max_features =\"sqrt\")\n",
        "rf.fit(X_train, y_train)\n",
        "predictions = rf.predict(X_test)\n",
        "\n",
        "r2_score(predictions, y_test)"
      ],
      "metadata": {
        "id": "7iXB4s3cgmbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpret Model Results"
      ],
      "metadata": {
        "id": "Jn7mjxU4inrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree"
      ],
      "metadata": {
        "id": "t2d5I4a0iph7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "tree = rf.estimators_[5]\n",
        "export_graphviz(tree, out_file = \"tree.dot\", feature_names = X_train, rounded = True, precision =1)\n",
        "(graph, )= pyplot.graph_from_dot_file(\"tree.dot\")\n",
        "graph.write_png(\"tree.png\")"
      ],
      "metadata": {
        "id": "MInlDrE7irzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Importance"
      ],
      "metadata": {
        "id": "l97WQBV5jU4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importances = list(rf.feature_importances_)\n",
        "feature_importances = [(feature,round(importance,2)) for feature, importance in zip(original_feature_list,importances)]\n",
        "feature_importances = sorted(fetaure_importances, key = lambda x: x[1],reverse =True)\n",
        "[print(\"variable: {:20} Importance: {}\".format(*pair)) for pair in feature_importances]"
      ],
      "metadata": {
        "id": "3yW64rq3jWK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the best two features got from Feature Importance building another model"
      ],
      "metadata": {
        "id": "twGaaU0dkFtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "rf_most_important = RandomForestRegressor(n_estimators =100, max_depth = 3, max_features =\"auto\")\n",
        "important_indices = [original_feature_list.index(\"temp_1\"), original_fetaure_list.index(\"average\")]\n",
        "train_important = original_train_features[:,important_indices]\n",
        "test_important = original_test_features[:,important_indices]\n",
        "\n",
        "rf_most_important.fit(train_important, original_trian_labels)\n",
        "predictions = rf_most_important.predict(test_important)\n",
        "errors = abs(predictions - original_test_labels)\n",
        "print(\"MAE :\", round(np.mean(errors),2), \"degrees.\")\n",
        "r2_score(predictions, original_test_labels)"
      ],
      "metadata": {
        "id": "LSPfrMDkkLu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XG Boosting"
      ],
      "metadata": {
        "id": "iM1tG2Ce8U-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = Original_train_features\n",
        "Y_train = Original_train_features\n",
        "X_test = original_test_features\n",
        "y_test = original_test_labels"
      ],
      "metadata": {
        "id": "XfHG0taB8We1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "XiABowFI8ldD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "for lr in [0.01, 0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.2,0.5,1]:\n",
        "  model = xgb.XGBRegressor(learning_rate =lr, n_estimators =100, verbostiy = 0)\n",
        "  model.fit(X_train,y_train)\n",
        "  model.score(X_test, y_test)\n",
        "  print(\"Learning rate :\", lr, \"Train score :\", modle.score(X_train, y_train),\"Corss_Val_score :\", np.men(corss_val_score(model,x_train)))\n",
        "  "
      ],
      "metadata": {
        "id": "Ubz4Dlj08qgB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}